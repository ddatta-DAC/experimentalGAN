{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./..')\n",
    "from evaluator import eval_module\n",
    "from tgan.model import TGANModel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_dims(DIR='us_import1'):\n",
    "    with open('./../generated_data_v1/{}/domain_dims.pkl'.format(DIR),'rb') as fh:\n",
    "        domain_dims = pickle.load(fh)\n",
    "    return domain_dims\n",
    "\n",
    "def convert_np_to_pd(data_np, domain_dims):\n",
    "    columns = list(domain_dims.keys())\n",
    "    df = pd.DataFrame(data= data_np, columns=columns)\n",
    "    return df, columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = np.load('./../generated_data_v1/us_import1/pos_data.npy')\n",
    "domain_dims = get_domain_dims()\n",
    "data_df,columns = convert_np_to_pd(real_data, domain_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = TGANModel([],\n",
    "    max_epoch=100,\n",
    "    steps_per_epoch=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/graph_builder/model_desc.py:29: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/graph_builder/model_desc.py:39: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/input_source/input_source.py:219: The name tf.FIFOQueue is deprecated. Please use tf.queue.FIFOQueue instead.\n",
      "\n",
      "\u001b[32m[1211 20:50:25 @input_source.py:222]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/summary.py:237: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/summary.py:27: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/summary.py:254: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/summary.py:264: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/collection.py:105: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/collection.py:33: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tgan/model.py:455: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tgan/model.py:458: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tgan/model.py:259: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/00/FC input: [200, 100]\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/models/fc.py:57: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/models/fc.py:67: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/00/FC output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/00/FC2 input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/00/FC2 output: [200, 582]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/00/FC3 input: [200, 582]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/00/FC3 output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/01/FC input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/01/FC output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/01/FC2 input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/01/FC2 output: [200, 3005]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/01/FC3 input: [200, 3005]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/01/FC3 output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/02/FC input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/02/FC output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/02/FC2 input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/02/FC2 output: [200, 1680]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/02/FC3 input: [200, 1680]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/02/FC3 output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/03/FC input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/03/FC output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/03/FC2 input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/03/FC2 output: [200, 279]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/03/FC3 input: [200, 279]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/03/FC3 output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/04/FC input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/04/FC output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/04/FC2 input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/04/FC2 output: [200, 63]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/04/FC3 input: [200, 63]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/04/FC3 output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/05/FC input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/05/FC output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/05/FC2 input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/05/FC2 output: [200, 131]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/05/FC3 input: [200, 131]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/05/FC3 output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/06/FC input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/06/FC output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/06/FC2 input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/06/FC2 output: [200, 95]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/06/FC3 input: [200, 95]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/06/FC3 output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/07/FC input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/07/FC output: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/07/FC2 input: [200, 100]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:134]\u001b[0m gen/LSTM/07/FC2 output: [200, 2819]\n",
      "\u001b[32m[1211 20:50:25 @registry.py:126]\u001b[0m gen/LSTM/07/FC3 input: [200, 2819]\n",
      "\u001b[32m[1211 20:50:26 @registry.py:134]\u001b[0m gen/LSTM/07/FC3 output: [200, 100]\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tgan/model.py:494: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tgan/model.py:443: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "\u001b[32m[1211 20:50:26 @registry.py:126]\u001b[0m discrim/dis_fc0/fc input: [200, 8654]\n",
      "\u001b[32m[1211 20:50:26 @registry.py:134]\u001b[0m discrim/dis_fc0/fc output: [200, 100]\n",
      "\u001b[32m[1211 20:50:26 @registry.py:126]\u001b[0m discrim/dis_fc0/fc_diversity input: [200, 100]\n",
      "\u001b[32m[1211 20:50:26 @registry.py:134]\u001b[0m discrim/dis_fc0/fc_diversity output: [200, 100]\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/models/batch_norm.py:204: The name tf.layers.BatchNormalization is deprecated. Please use tf.compat.v1.layers.BatchNormalization instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/models/batch_norm.py:212: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "\u001b[32m[1211 20:50:26 @registry.py:126]\u001b[0m discrim/dis_fc_top input: [200, 110]\n",
      "\u001b[32m[1211 20:50:26 @registry.py:134]\u001b[0m discrim/dis_fc_top output: [200, 1]\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tgan/model.py:118: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tgan/model.py:551: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "\u001b[32m[1211 20:50:30 @logger.py:83]\u001b[0m Existing log file 'output/logs/log.log' backuped to 'output/logs/log.log.1211-205030'\n",
      "\u001b[32m[1211 20:50:30 @logger.py:90]\u001b[0m Argv: /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/ipykernel_launcher.py -f /home/ddatta/.local/share/jupyter/runtime/kernel-7d056752-020c-4204-a1a2-70a0a4fe76a6.json\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/callbacks/saver.py:43: The name tf.gfile.IsDirectory is deprecated. Please use tf.io.gfile.isdir instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/callbacks/saver.py:44: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/common.py:41: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "\u001b[32m[1211 20:50:30 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n",
      "\u001b[0mname                              shape          #elements\n",
      "--------------------------------  -----------  -----------\n",
      "gen/LSTM/go:0                     [1, 100]             100\n",
      "gen/LSTM/lstm_cell/kernel:0       [500, 400]        200000\n",
      "gen/LSTM/lstm_cell/bias:0         [400]                400\n",
      "gen/LSTM/00/FC/W:0                [100, 100]         10000\n",
      "gen/LSTM/00/FC/b:0                [100]                100\n",
      "gen/LSTM/00/FC2/W:0               [100, 582]         58200\n",
      "gen/LSTM/00/FC2/b:0               [582]                582\n",
      "gen/LSTM/00/FC3/W:0               [582, 100]         58200\n",
      "gen/LSTM/00/FC3/b:0               [100]                100\n",
      "gen/LSTM/00/attw:0                [1, 1, 1]              1\n",
      "gen/LSTM/01/FC/W:0                [100, 100]         10000\n",
      "gen/LSTM/01/FC/b:0                [100]                100\n",
      "gen/LSTM/01/FC2/W:0               [100, 3005]       300500\n",
      "gen/LSTM/01/FC2/b:0               [3005]              3005\n",
      "gen/LSTM/01/FC3/W:0               [3005, 100]       300500\n",
      "gen/LSTM/01/FC3/b:0               [100]                100\n",
      "gen/LSTM/01/attw:0                [2, 1, 1]              2\n",
      "gen/LSTM/02/FC/W:0                [100, 100]         10000\n",
      "gen/LSTM/02/FC/b:0                [100]                100\n",
      "gen/LSTM/02/FC2/W:0               [100, 1680]       168000\n",
      "gen/LSTM/02/FC2/b:0               [1680]              1680\n",
      "gen/LSTM/02/FC3/W:0               [1680, 100]       168000\n",
      "gen/LSTM/02/FC3/b:0               [100]                100\n",
      "gen/LSTM/02/attw:0                [3, 1, 1]              3\n",
      "gen/LSTM/03/FC/W:0                [100, 100]         10000\n",
      "gen/LSTM/03/FC/b:0                [100]                100\n",
      "gen/LSTM/03/FC2/W:0               [100, 279]         27900\n",
      "gen/LSTM/03/FC2/b:0               [279]                279\n",
      "gen/LSTM/03/FC3/W:0               [279, 100]         27900\n",
      "gen/LSTM/03/FC3/b:0               [100]                100\n",
      "gen/LSTM/03/attw:0                [4, 1, 1]              4\n",
      "gen/LSTM/04/FC/W:0                [100, 100]         10000\n",
      "gen/LSTM/04/FC/b:0                [100]                100\n",
      "gen/LSTM/04/FC2/W:0               [100, 63]           6300\n",
      "gen/LSTM/04/FC2/b:0               [63]                  63\n",
      "gen/LSTM/04/FC3/W:0               [63, 100]           6300\n",
      "gen/LSTM/04/FC3/b:0               [100]                100\n",
      "gen/LSTM/04/attw:0                [5, 1, 1]              5\n",
      "gen/LSTM/05/FC/W:0                [100, 100]         10000\n",
      "gen/LSTM/05/FC/b:0                [100]                100\n",
      "gen/LSTM/05/FC2/W:0               [100, 131]         13100\n",
      "gen/LSTM/05/FC2/b:0               [131]                131\n",
      "gen/LSTM/05/FC3/W:0               [131, 100]         13100\n",
      "gen/LSTM/05/FC3/b:0               [100]                100\n",
      "gen/LSTM/05/attw:0                [6, 1, 1]              6\n",
      "gen/LSTM/06/FC/W:0                [100, 100]         10000\n",
      "gen/LSTM/06/FC/b:0                [100]                100\n",
      "gen/LSTM/06/FC2/W:0               [100, 95]           9500\n",
      "gen/LSTM/06/FC2/b:0               [95]                  95\n",
      "gen/LSTM/06/FC3/W:0               [95, 100]           9500\n",
      "gen/LSTM/06/FC3/b:0               [100]                100\n",
      "gen/LSTM/06/attw:0                [7, 1, 1]              7\n",
      "gen/LSTM/07/FC/W:0                [100, 100]         10000\n",
      "gen/LSTM/07/FC/b:0                [100]                100\n",
      "gen/LSTM/07/FC2/W:0               [100, 2819]       281900\n",
      "gen/LSTM/07/FC2/b:0               [2819]              2819\n",
      "gen/LSTM/07/FC3/W:0               [2819, 100]       281900\n",
      "gen/LSTM/07/FC3/b:0               [100]                100\n",
      "gen/LSTM/07/attw:0                [8, 1, 1]              8\n",
      "discrim/dis_fc0/fc/W:0            [8654, 100]       865400\n",
      "discrim/dis_fc0/fc/b:0            [100]                100\n",
      "discrim/dis_fc0/fc_diversity/W:0  [100, 100]         10000\n",
      "discrim/dis_fc0/fc_diversity/b:0  [100]                100\n",
      "discrim/dis_fc0/bn/beta:0         [110]                110\n",
      "discrim/dis_fc_top/W:0            [110, 1]             110\n",
      "discrim/dis_fc_top/b:0            [1]                    1\u001b[36m\n",
      "Number of trainable variables: 66\n",
      "Number of parameters (elements): 2897411\n",
      "Storage space needed for all trainable variables: 11.05MB\u001b[0m\n",
      "\u001b[32m[1211 20:50:30 @base.py:209]\u001b[0m Setup callbacks graph ...\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/callbacks/graph.py:54: The name tf.train.SessionRunArgs is deprecated. Please use tf.estimator.SessionRunArgs instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/common.py:75: The name tf.VariableScope is deprecated. Please use tf.compat.v1.VariableScope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/common.py:77: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/callbacks/steps.py:117: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/callbacks/saver.py:55: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/callbacks/saver.py:59: The name tf.train.SaverDef is deprecated. Please use tf.compat.v1.train.SaverDef instead.\n",
      "\n",
      "\u001b[32m[1211 20:50:31 @summary.py:46]\u001b[0m [MovingAverageSummary] 6 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n",
      "\u001b[32m[1211 20:50:31 @summary.py:93]\u001b[0m Summarizing collection 'summaries' of size 9.\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/callbacks/summary.py:94: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "\u001b[32m[1211 20:50:31 @graph.py:98]\u001b[0m Applying collection UPDATE_OPS of 4 ops.\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/callbacks/monitor.py:261: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "\u001b[32m[1211 20:50:31 @base.py:230]\u001b[0m Creating the session ...\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/sesscreate.py:42: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/sesscreate.py:71: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/sesscreate.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
      "Instructions for updating:\n",
      "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/sesscreate.py:72: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/sesscreate.py:73: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/train/base.py:254: The name tf.train.MonitoredSession is deprecated. Please use tf.compat.v1.train.MonitoredSession instead.\n",
      "\n",
      "\u001b[32m[1211 20:50:32 @base.py:236]\u001b[0m Initializing the session ...\n",
      "\u001b[32m[1211 20:50:32 @base.py:243]\u001b[0m Graph Finalized.\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/common.py:89: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/tfutils/common.py:90: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "\u001b[32m[1211 20:50:32 @concurrency.py:38]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/callbacks/monitor.py:309: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "\u001b[32m[1211 20:50:33 @monitor.py:352]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m History epoch=100 from JSON is not the predecessor of the current starting_epoch=1\n",
      "\u001b[32m[1211 20:50:33 @monitor.py:353]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. \n",
      "\u001b[32m[1211 20:50:33 @monitor.py:360]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Now, we will train with starting_epoch=1 and backup old json to output/logs/stats.json.1211-205033\n",
      "\u001b[32m[1211 20:50:33 @base.py:275]\u001b[0m Start Epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#########9|999/1000[03:40<00:00, 4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/callbacks/monitor.py:148: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|1000/1000[03:42<00:00, 4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 20:54:15 @base.py:285]\u001b[0m Epoch 1 (global_step 1000) finished, time:3 minutes 42 seconds.\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorpack/callbacks/saver.py:77: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 20:54:15 @saver.py:79]\u001b[0m Model saved to output/model/model-1000.\n",
      "\u001b[32m[1211 20:54:15 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.805\n",
      "\u001b[32m[1211 20:54:15 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.31\n",
      "\u001b[32m[1211 20:54:15 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65682\n",
      "\u001b[32m[1211 20:54:15 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 1.0715\n",
      "\u001b[32m[1211 20:54:15 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.033736\n",
      "\u001b[32m[1211 20:54:15 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 1.0378\n",
      "\u001b[32m[1211 20:54:15 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 20:54:15 @base.py:275]\u001b[0m Start Epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|1000/1000[03:33<00:00, 4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 20:57:49 @base.py:285]\u001b[0m Epoch 2 (global_step 2000) finished, time:3 minutes 33 seconds.\n",
      "\u001b[32m[1211 20:57:49 @saver.py:79]\u001b[0m Model saved to output/model/model-2000.\n",
      "\u001b[32m[1211 20:57:49 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.89\n",
      "\u001b[32m[1211 20:57:49 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.175\n",
      "\u001b[32m[1211 20:57:49 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.6566\n",
      "\u001b[32m[1211 20:57:49 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.9813\n",
      "\u001b[32m[1211 20:57:49 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.019831\n",
      "\u001b[32m[1211 20:57:49 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.96147\n",
      "\u001b[32m[1211 20:57:49 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 20:57:49 @base.py:275]\u001b[0m Start Epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:33<00:00, 4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:01:22 @base.py:285]\u001b[0m Epoch 3 (global_step 3000) finished, time:3 minutes 33 seconds.\n",
      "\u001b[32m[1211 21:01:22 @saver.py:79]\u001b[0m Model saved to output/model/model-3000.\n",
      "\u001b[32m[1211 21:01:22 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.95\n",
      "\u001b[32m[1211 21:01:22 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.095\n",
      "\u001b[32m[1211 21:01:22 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.63951\n",
      "\u001b[32m[1211 21:01:22 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.97112\n",
      "\u001b[32m[1211 21:01:22 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.018911\n",
      "\u001b[32m[1211 21:01:22 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.95221\n",
      "\u001b[32m[1211 21:01:22 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:01:22 @base.py:275]\u001b[0m Start Epoch 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:32<00:00, 4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:04:54 @base.py:285]\u001b[0m Epoch 4 (global_step 4000) finished, time:3 minutes 32 seconds.\n",
      "\u001b[32m[1211 21:04:54 @saver.py:79]\u001b[0m Model saved to output/model/model-4000.\n",
      "\u001b[32m[1211 21:04:54 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.905\n",
      "\u001b[32m[1211 21:04:54 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.065\n",
      "\u001b[32m[1211 21:04:54 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.6585\n",
      "\u001b[32m[1211 21:04:54 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.94384\n",
      "\u001b[32m[1211 21:04:54 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.020526\n",
      "\u001b[32m[1211 21:04:54 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.92332\n",
      "\u001b[32m[1211 21:04:54 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:04:54 @base.py:275]\u001b[0m Start Epoch 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:31<00:00, 4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:08:25 @base.py:285]\u001b[0m Epoch 5 (global_step 5000) finished, time:3 minutes 31 seconds.\n",
      "\u001b[32m[1211 21:08:26 @saver.py:79]\u001b[0m Model saved to output/model/model-5000.\n",
      "\u001b[32m[1211 21:08:26 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.925\n",
      "\u001b[32m[1211 21:08:26 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.175\n",
      "\u001b[32m[1211 21:08:26 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64241\n",
      "\u001b[32m[1211 21:08:26 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96499\n",
      "\u001b[32m[1211 21:08:26 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.022168\n",
      "\u001b[32m[1211 21:08:26 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94283\n",
      "\u001b[32m[1211 21:08:26 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:08:26 @base.py:275]\u001b[0m Start Epoch 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:28<00:00, 4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:11:54 @base.py:285]\u001b[0m Epoch 6 (global_step 6000) finished, time:3 minutes 28 seconds.\n",
      "\u001b[32m[1211 21:11:54 @saver.py:79]\u001b[0m Model saved to output/model/model-6000.\n",
      "\u001b[32m[1211 21:11:54 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.95\n",
      "\u001b[32m[1211 21:11:54 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.14\n",
      "\u001b[32m[1211 21:11:54 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.6479\n",
      "\u001b[32m[1211 21:11:54 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.98222\n",
      "\u001b[32m[1211 21:11:54 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.025055\n",
      "\u001b[32m[1211 21:11:54 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.95716\n",
      "\u001b[32m[1211 21:11:54 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:11:54 @base.py:275]\u001b[0m Start Epoch 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:30<00:00, 4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:15:25 @base.py:285]\u001b[0m Epoch 7 (global_step 7000) finished, time:3 minutes 30 seconds.\n",
      "\u001b[32m[1211 21:15:25 @saver.py:79]\u001b[0m Model saved to output/model/model-7000.\n",
      "\u001b[32m[1211 21:15:25 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.92\n",
      "\u001b[32m[1211 21:15:25 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.185\n",
      "\u001b[32m[1211 21:15:25 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65564\n",
      "\u001b[32m[1211 21:15:25 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.95427\n",
      "\u001b[32m[1211 21:15:25 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.016169\n",
      "\u001b[32m[1211 21:15:25 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.9381\n",
      "\u001b[32m[1211 21:15:25 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:15:25 @base.py:275]\u001b[0m Start Epoch 8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:29<00:00, 4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:18:55 @base.py:285]\u001b[0m Epoch 8 (global_step 8000) finished, time:3 minutes 29 seconds.\n",
      "\u001b[32m[1211 21:18:55 @saver.py:79]\u001b[0m Model saved to output/model/model-8000.\n",
      "\u001b[32m[1211 21:18:55 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.915\n",
      "\u001b[32m[1211 21:18:55 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.18\n",
      "\u001b[32m[1211 21:18:55 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65021\n",
      "\u001b[32m[1211 21:18:55 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96773\n",
      "\u001b[32m[1211 21:18:55 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.018445\n",
      "\u001b[32m[1211 21:18:55 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94928\n",
      "\u001b[32m[1211 21:18:55 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:18:55 @base.py:275]\u001b[0m Start Epoch 9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:29<00:00, 4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:22:24 @base.py:285]\u001b[0m Epoch 9 (global_step 9000) finished, time:3 minutes 29 seconds.\n",
      "\u001b[32m[1211 21:22:25 @saver.py:79]\u001b[0m Model saved to output/model/model-9000.\n",
      "\u001b[32m[1211 21:22:25 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.925\n",
      "\u001b[32m[1211 21:22:25 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.16\n",
      "\u001b[32m[1211 21:22:25 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.63895\n",
      "\u001b[32m[1211 21:22:25 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.95948\n",
      "\u001b[32m[1211 21:22:25 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.017449\n",
      "\u001b[32m[1211 21:22:25 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94203\n",
      "\u001b[32m[1211 21:22:25 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:22:25 @base.py:275]\u001b[0m Start Epoch 10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:29<00:00, 4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:25:54 @base.py:285]\u001b[0m Epoch 10 (global_step 10000) finished, time:3 minutes 29 seconds.\n",
      "\u001b[32m[1211 21:25:54 @saver.py:79]\u001b[0m Model saved to output/model/model-10000.\n",
      "\u001b[32m[1211 21:25:54 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.895\n",
      "\u001b[32m[1211 21:25:54 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.165\n",
      "\u001b[32m[1211 21:25:54 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64578\n",
      "\u001b[32m[1211 21:25:54 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.9698\n",
      "\u001b[32m[1211 21:25:54 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.015337\n",
      "\u001b[32m[1211 21:25:54 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.95447\n",
      "\u001b[32m[1211 21:25:54 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:25:54 @base.py:275]\u001b[0m Start Epoch 11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:29<00:00, 4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:29:23 @base.py:285]\u001b[0m Epoch 11 (global_step 11000) finished, time:3 minutes 29 seconds.\n",
      "WARNING:tensorflow:From /home/ddatta/anaconda3/envs/graph1/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "\u001b[32m[1211 21:29:23 @saver.py:79]\u001b[0m Model saved to output/model/model-11000.\n",
      "\u001b[32m[1211 21:29:23 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.91\n",
      "\u001b[32m[1211 21:29:23 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.17\n",
      "\u001b[32m[1211 21:29:23 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.6465\n",
      "\u001b[32m[1211 21:29:23 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96948\n",
      "\u001b[32m[1211 21:29:23 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.015273\n",
      "\u001b[32m[1211 21:29:23 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.95421\n",
      "\u001b[32m[1211 21:29:23 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:29:23 @base.py:275]\u001b[0m Start Epoch 12 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:29<00:00, 4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:32:53 @base.py:285]\u001b[0m Epoch 12 (global_step 12000) finished, time:3 minutes 29 seconds.\n",
      "\u001b[32m[1211 21:32:53 @saver.py:79]\u001b[0m Model saved to output/model/model-12000.\n",
      "\u001b[32m[1211 21:32:53 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.93\n",
      "\u001b[32m[1211 21:32:53 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.215\n",
      "\u001b[32m[1211 21:32:53 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.63083\n",
      "\u001b[32m[1211 21:32:53 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 1.0087\n",
      "\u001b[32m[1211 21:32:53 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.026584\n",
      "\u001b[32m[1211 21:32:53 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.98215\n",
      "\u001b[32m[1211 21:32:53 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:32:53 @base.py:275]\u001b[0m Start Epoch 13 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:27<00:00, 4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:36:21 @base.py:285]\u001b[0m Epoch 13 (global_step 13000) finished, time:3 minutes 27 seconds.\n",
      "\u001b[32m[1211 21:36:21 @saver.py:79]\u001b[0m Model saved to output/model/model-13000.\n",
      "\u001b[32m[1211 21:36:21 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.935\n",
      "\u001b[32m[1211 21:36:21 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.175\n",
      "\u001b[32m[1211 21:36:21 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.63844\n",
      "\u001b[32m[1211 21:36:21 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 1.0002\n",
      "\u001b[32m[1211 21:36:21 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.014597\n",
      "\u001b[32m[1211 21:36:21 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.98556\n",
      "\u001b[32m[1211 21:36:21 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:36:21 @base.py:275]\u001b[0m Start Epoch 14 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:28<00:00, 4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:39:49 @base.py:285]\u001b[0m Epoch 14 (global_step 14000) finished, time:3 minutes 28 seconds.\n",
      "\u001b[32m[1211 21:39:50 @saver.py:79]\u001b[0m Model saved to output/model/model-14000.\n",
      "\u001b[32m[1211 21:39:50 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.93\n",
      "\u001b[32m[1211 21:39:50 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.195\n",
      "\u001b[32m[1211 21:39:50 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.63345\n",
      "\u001b[32m[1211 21:39:50 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.99728\n",
      "\u001b[32m[1211 21:39:50 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.020093\n",
      "\u001b[32m[1211 21:39:50 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.97719\n",
      "\u001b[32m[1211 21:39:50 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:39:50 @base.py:275]\u001b[0m Start Epoch 15 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:28<00:00, 4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:43:18 @base.py:285]\u001b[0m Epoch 15 (global_step 15000) finished, time:3 minutes 28 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:43:18 @saver.py:79]\u001b[0m Model saved to output/model/model-15000.\n",
      "\u001b[32m[1211 21:43:18 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.915\n",
      "\u001b[32m[1211 21:43:18 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.17\n",
      "\u001b[32m[1211 21:43:18 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.6484\n",
      "\u001b[32m[1211 21:43:18 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.95981\n",
      "\u001b[32m[1211 21:43:18 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.014431\n",
      "\u001b[32m[1211 21:43:18 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94538\n",
      "\u001b[32m[1211 21:43:18 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:43:18 @base.py:275]\u001b[0m Start Epoch 16 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|1000/1000[03:26<00:00, 4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:46:45 @base.py:285]\u001b[0m Epoch 16 (global_step 16000) finished, time:3 minutes 26 seconds.\n",
      "\u001b[32m[1211 21:46:45 @saver.py:79]\u001b[0m Model saved to output/model/model-16000.\n",
      "\u001b[32m[1211 21:46:45 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.935\n",
      "\u001b[32m[1211 21:46:45 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.14\n",
      "\u001b[32m[1211 21:46:45 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64503\n",
      "\u001b[32m[1211 21:46:45 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96058\n",
      "\u001b[32m[1211 21:46:45 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.016433\n",
      "\u001b[32m[1211 21:46:45 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94415\n",
      "\u001b[32m[1211 21:46:45 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:46:45 @base.py:275]\u001b[0m Start Epoch 17 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:30<00:00, 4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:50:16 @base.py:285]\u001b[0m Epoch 17 (global_step 17000) finished, time:3 minutes 30 seconds.\n",
      "\u001b[32m[1211 21:50:16 @saver.py:79]\u001b[0m Model saved to output/model/model-17000.\n",
      "\u001b[32m[1211 21:50:16 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.925\n",
      "\u001b[32m[1211 21:50:16 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.195\n",
      "\u001b[32m[1211 21:50:16 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64757\n",
      "\u001b[32m[1211 21:50:16 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.9787\n",
      "\u001b[32m[1211 21:50:16 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.019486\n",
      "\u001b[32m[1211 21:50:16 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.95922\n",
      "\u001b[32m[1211 21:50:16 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:50:16 @base.py:275]\u001b[0m Start Epoch 18 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:28<00:00, 4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:53:45 @base.py:285]\u001b[0m Epoch 18 (global_step 18000) finished, time:3 minutes 28 seconds.\n",
      "\u001b[32m[1211 21:53:45 @saver.py:79]\u001b[0m Model saved to output/model/model-18000.\n",
      "\u001b[32m[1211 21:53:45 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.915\n",
      "\u001b[32m[1211 21:53:45 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.15\n",
      "\u001b[32m[1211 21:53:45 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.66609\n",
      "\u001b[32m[1211 21:53:45 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96668\n",
      "\u001b[32m[1211 21:53:45 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.014439\n",
      "\u001b[32m[1211 21:53:45 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.95224\n",
      "\u001b[32m[1211 21:53:45 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:53:45 @base.py:275]\u001b[0m Start Epoch 19 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:27<00:00, 4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 21:57:12 @base.py:285]\u001b[0m Epoch 19 (global_step 19000) finished, time:3 minutes 27 seconds.\n",
      "\u001b[32m[1211 21:57:12 @saver.py:79]\u001b[0m Model saved to output/model/model-19000.\n",
      "\u001b[32m[1211 21:57:12 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.93\n",
      "\u001b[32m[1211 21:57:12 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.16\n",
      "\u001b[32m[1211 21:57:12 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64885\n",
      "\u001b[32m[1211 21:57:12 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.98248\n",
      "\u001b[32m[1211 21:57:12 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.019514\n",
      "\u001b[32m[1211 21:57:12 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.96297\n",
      "\u001b[32m[1211 21:57:12 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 21:57:12 @base.py:275]\u001b[0m Start Epoch 20 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:27<00:00, 4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:00:40 @base.py:285]\u001b[0m Epoch 20 (global_step 20000) finished, time:3 minutes 27 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:00:40 @saver.py:79]\u001b[0m Model saved to output/model/model-20000.\n",
      "\u001b[32m[1211 22:00:40 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.92\n",
      "\u001b[32m[1211 22:00:40 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.2\n",
      "\u001b[32m[1211 22:00:40 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64059\n",
      "\u001b[32m[1211 22:00:40 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96871\n",
      "\u001b[32m[1211 22:00:40 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.016401\n",
      "\u001b[32m[1211 22:00:40 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.95231\n",
      "\u001b[32m[1211 22:00:40 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:00:40 @base.py:275]\u001b[0m Start Epoch 21 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|1000/1000[03:26<00:00, 4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:04:06 @base.py:285]\u001b[0m Epoch 21 (global_step 21000) finished, time:3 minutes 26 seconds.\n",
      "\u001b[32m[1211 22:04:07 @saver.py:79]\u001b[0m Model saved to output/model/model-21000.\n",
      "\u001b[32m[1211 22:04:07 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.95\n",
      "\u001b[32m[1211 22:04:07 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.15\n",
      "\u001b[32m[1211 22:04:07 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64145\n",
      "\u001b[32m[1211 22:04:07 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.98122\n",
      "\u001b[32m[1211 22:04:07 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.019073\n",
      "\u001b[32m[1211 22:04:07 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.96214\n",
      "\u001b[32m[1211 22:04:07 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:04:07 @base.py:275]\u001b[0m Start Epoch 22 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:28<00:00, 4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:07:35 @base.py:285]\u001b[0m Epoch 22 (global_step 22000) finished, time:3 minutes 28 seconds.\n",
      "\u001b[32m[1211 22:07:35 @saver.py:79]\u001b[0m Model saved to output/model/model-22000.\n",
      "\u001b[32m[1211 22:07:35 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.9\n",
      "\u001b[32m[1211 22:07:35 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.115\n",
      "\u001b[32m[1211 22:07:35 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65961\n",
      "\u001b[32m[1211 22:07:35 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.94555\n",
      "\u001b[32m[1211 22:07:35 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.021679\n",
      "\u001b[32m[1211 22:07:35 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.92387\n",
      "\u001b[32m[1211 22:07:35 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:07:35 @base.py:275]\u001b[0m Start Epoch 23 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:27<00:00, 4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:11:02 @base.py:285]\u001b[0m Epoch 23 (global_step 23000) finished, time:3 minutes 27 seconds.\n",
      "\u001b[32m[1211 22:11:02 @saver.py:79]\u001b[0m Model saved to output/model/model-23000.\n",
      "\u001b[32m[1211 22:11:02 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.95\n",
      "\u001b[32m[1211 22:11:02 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.105\n",
      "\u001b[32m[1211 22:11:02 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64588\n",
      "\u001b[32m[1211 22:11:02 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.97266\n",
      "\u001b[32m[1211 22:11:02 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.021172\n",
      "\u001b[32m[1211 22:11:02 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.95149\n",
      "\u001b[32m[1211 22:11:02 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:11:02 @base.py:275]\u001b[0m Start Epoch 24 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:28<00:00, 4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:14:31 @base.py:285]\u001b[0m Epoch 24 (global_step 24000) finished, time:3 minutes 28 seconds.\n",
      "\u001b[32m[1211 22:14:31 @saver.py:79]\u001b[0m Model saved to output/model/model-24000.\n",
      "\u001b[32m[1211 22:14:31 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.895\n",
      "\u001b[32m[1211 22:14:31 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.235\n",
      "\u001b[32m[1211 22:14:31 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.63596\n",
      "\u001b[32m[1211 22:14:31 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.95794\n",
      "\u001b[32m[1211 22:14:31 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.016231\n",
      "\u001b[32m[1211 22:14:31 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94171\n",
      "\u001b[32m[1211 22:14:31 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:14:31 @base.py:275]\u001b[0m Start Epoch 25 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:28<00:00, 4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:17:59 @base.py:285]\u001b[0m Epoch 25 (global_step 25000) finished, time:3 minutes 28 seconds.\n",
      "\u001b[32m[1211 22:17:59 @saver.py:79]\u001b[0m Model saved to output/model/model-25000.\n",
      "\u001b[32m[1211 22:17:59 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.935\n",
      "\u001b[32m[1211 22:17:59 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.15\n",
      "\u001b[32m[1211 22:17:59 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64969\n",
      "\u001b[32m[1211 22:17:59 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.97072\n",
      "\u001b[32m[1211 22:17:59 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.015835\n",
      "\u001b[32m[1211 22:17:59 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.95489\n",
      "\u001b[32m[1211 22:17:59 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:17:59 @base.py:275]\u001b[0m Start Epoch 26 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:26<00:00, 4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:21:26 @base.py:285]\u001b[0m Epoch 26 (global_step 26000) finished, time:3 minutes 26 seconds.\n",
      "\u001b[32m[1211 22:21:26 @saver.py:79]\u001b[0m Model saved to output/model/model-26000.\n",
      "\u001b[32m[1211 22:21:26 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.915\n",
      "\u001b[32m[1211 22:21:26 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.17\n",
      "\u001b[32m[1211 22:21:26 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64438\n",
      "\u001b[32m[1211 22:21:26 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.94817\n",
      "\u001b[32m[1211 22:21:26 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.016426\n",
      "\u001b[32m[1211 22:21:26 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.93174\n",
      "\u001b[32m[1211 22:21:26 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:21:26 @base.py:275]\u001b[0m Start Epoch 27 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:27<00:00, 4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:24:53 @base.py:285]\u001b[0m Epoch 27 (global_step 27000) finished, time:3 minutes 27 seconds.\n",
      "\u001b[32m[1211 22:24:53 @saver.py:79]\u001b[0m Model saved to output/model/model-27000.\n",
      "\u001b[32m[1211 22:24:53 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.94\n",
      "\u001b[32m[1211 22:24:53 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.135\n",
      "\u001b[32m[1211 22:24:53 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64791\n",
      "\u001b[32m[1211 22:24:53 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96946\n",
      "\u001b[32m[1211 22:24:53 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.018376\n",
      "\u001b[32m[1211 22:24:53 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.95109\n",
      "\u001b[32m[1211 22:24:53 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:24:53 @base.py:275]\u001b[0m Start Epoch 28 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:28<00:00, 4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:28:21 @base.py:285]\u001b[0m Epoch 28 (global_step 28000) finished, time:3 minutes 28 seconds.\n",
      "\u001b[32m[1211 22:28:21 @saver.py:79]\u001b[0m Model saved to output/model/model-28000.\n",
      "\u001b[32m[1211 22:28:21 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.9\n",
      "\u001b[32m[1211 22:28:21 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.165\n",
      "\u001b[32m[1211 22:28:21 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65119\n",
      "\u001b[32m[1211 22:28:21 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96395\n",
      "\u001b[32m[1211 22:28:21 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.016157\n",
      "\u001b[32m[1211 22:28:21 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94779\n",
      "\u001b[32m[1211 22:28:21 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:28:21 @base.py:275]\u001b[0m Start Epoch 29 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:26<00:00, 4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:31:47 @base.py:285]\u001b[0m Epoch 29 (global_step 29000) finished, time:3 minutes 26 seconds.\n",
      "\u001b[32m[1211 22:31:48 @saver.py:79]\u001b[0m Model saved to output/model/model-29000.\n",
      "\u001b[32m[1211 22:31:48 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.895\n",
      "\u001b[32m[1211 22:31:48 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.155\n",
      "\u001b[32m[1211 22:31:48 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65668\n",
      "\u001b[32m[1211 22:31:48 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.9642\n",
      "\u001b[32m[1211 22:31:48 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.014625\n",
      "\u001b[32m[1211 22:31:48 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94958\n",
      "\u001b[32m[1211 22:31:48 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:31:48 @base.py:275]\u001b[0m Start Epoch 30 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:28<00:00, 4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:35:16 @base.py:285]\u001b[0m Epoch 30 (global_step 30000) finished, time:3 minutes 28 seconds.\n",
      "\u001b[32m[1211 22:35:17 @saver.py:79]\u001b[0m Model saved to output/model/model-30000.\n",
      "\u001b[32m[1211 22:35:17 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.945\n",
      "\u001b[32m[1211 22:35:17 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.215\n",
      "\u001b[32m[1211 22:35:17 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.63093\n",
      "\u001b[32m[1211 22:35:17 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.99406\n",
      "\u001b[32m[1211 22:35:17 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.01571\n",
      "\u001b[32m[1211 22:35:17 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.97835\n",
      "\u001b[32m[1211 22:35:17 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:35:17 @base.py:275]\u001b[0m Start Epoch 31 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:29<00:00, 4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:38:46 @base.py:285]\u001b[0m Epoch 31 (global_step 31000) finished, time:3 minutes 29 seconds.\n",
      "\u001b[32m[1211 22:38:46 @saver.py:79]\u001b[0m Model saved to output/model/model-31000.\n",
      "\u001b[32m[1211 22:38:46 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.92\n",
      "\u001b[32m[1211 22:38:46 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.205\n",
      "\u001b[32m[1211 22:38:46 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64252\n",
      "\u001b[32m[1211 22:38:46 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96202\n",
      "\u001b[32m[1211 22:38:46 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.01572\n",
      "\u001b[32m[1211 22:38:46 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.9463\n",
      "\u001b[32m[1211 22:38:46 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:38:46 @base.py:275]\u001b[0m Start Epoch 32 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:25<00:00, 4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:42:11 @base.py:285]\u001b[0m Epoch 32 (global_step 32000) finished, time:3 minutes 25 seconds.\n",
      "\u001b[32m[1211 22:42:12 @saver.py:79]\u001b[0m Model saved to output/model/model-32000.\n",
      "\u001b[32m[1211 22:42:12 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.91\n",
      "\u001b[32m[1211 22:42:12 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.155\n",
      "\u001b[32m[1211 22:42:12 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.66062\n",
      "\u001b[32m[1211 22:42:12 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.97439\n",
      "\u001b[32m[1211 22:42:12 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.015599\n",
      "\u001b[32m[1211 22:42:12 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.95879\n",
      "\u001b[32m[1211 22:42:12 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:42:12 @base.py:275]\u001b[0m Start Epoch 33 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:27<00:00, 4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:45:39 @base.py:285]\u001b[0m Epoch 33 (global_step 33000) finished, time:3 minutes 27 seconds.\n",
      "\u001b[32m[1211 22:45:39 @saver.py:79]\u001b[0m Model saved to output/model/model-33000.\n",
      "\u001b[32m[1211 22:45:39 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.915\n",
      "\u001b[32m[1211 22:45:39 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.15\n",
      "\u001b[32m[1211 22:45:39 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.656\n",
      "\u001b[32m[1211 22:45:39 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.97894\n",
      "\u001b[32m[1211 22:45:39 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.018214\n",
      "\u001b[32m[1211 22:45:39 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.96072\n",
      "\u001b[32m[1211 22:45:39 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:45:39 @base.py:275]\u001b[0m Start Epoch 34 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:27<00:00, 4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:49:07 @base.py:285]\u001b[0m Epoch 34 (global_step 34000) finished, time:3 minutes 27 seconds.\n",
      "\u001b[32m[1211 22:49:07 @saver.py:79]\u001b[0m Model saved to output/model/model-34000.\n",
      "\u001b[32m[1211 22:49:07 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.925\n",
      "\u001b[32m[1211 22:49:07 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.15\n",
      "\u001b[32m[1211 22:49:07 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65589\n",
      "\u001b[32m[1211 22:49:07 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.95681\n",
      "\u001b[32m[1211 22:49:07 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.013656\n",
      "\u001b[32m[1211 22:49:07 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94315\n",
      "\u001b[32m[1211 22:49:07 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:49:07 @base.py:275]\u001b[0m Start Epoch 35 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:26<00:00, 4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:52:34 @base.py:285]\u001b[0m Epoch 35 (global_step 35000) finished, time:3 minutes 26 seconds.\n",
      "\u001b[32m[1211 22:52:34 @saver.py:79]\u001b[0m Model saved to output/model/model-35000.\n",
      "\u001b[32m[1211 22:52:34 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.93\n",
      "\u001b[32m[1211 22:52:34 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.165\n",
      "\u001b[32m[1211 22:52:34 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.6275\n",
      "\u001b[32m[1211 22:52:34 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 1.0096\n",
      "\u001b[32m[1211 22:52:34 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.015988\n",
      "\u001b[32m[1211 22:52:34 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.99361\n",
      "\u001b[32m[1211 22:52:34 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:52:34 @base.py:275]\u001b[0m Start Epoch 36 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:26<00:00, 4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:56:00 @base.py:285]\u001b[0m Epoch 36 (global_step 36000) finished, time:3 minutes 26 seconds.\n",
      "\u001b[32m[1211 22:56:00 @saver.py:79]\u001b[0m Model saved to output/model/model-36000.\n",
      "\u001b[32m[1211 22:56:00 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.905\n",
      "\u001b[32m[1211 22:56:00 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.215\n",
      "\u001b[32m[1211 22:56:00 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65586\n",
      "\u001b[32m[1211 22:56:00 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.94456\n",
      "\u001b[32m[1211 22:56:00 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.015922\n",
      "\u001b[32m[1211 22:56:00 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.92864\n",
      "\u001b[32m[1211 22:56:00 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:56:00 @base.py:275]\u001b[0m Start Epoch 37 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:26<00:00, 4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 22:59:26 @base.py:285]\u001b[0m Epoch 37 (global_step 37000) finished, time:3 minutes 26 seconds.\n",
      "\u001b[32m[1211 22:59:27 @saver.py:79]\u001b[0m Model saved to output/model/model-37000.\n",
      "\u001b[32m[1211 22:59:27 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.925\n",
      "\u001b[32m[1211 22:59:27 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.17\n",
      "\u001b[32m[1211 22:59:27 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.654\n",
      "\u001b[32m[1211 22:59:27 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96148\n",
      "\u001b[32m[1211 22:59:27 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.016383\n",
      "\u001b[32m[1211 22:59:27 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.9451\n",
      "\u001b[32m[1211 22:59:27 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 22:59:27 @base.py:275]\u001b[0m Start Epoch 38 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:27<00:00, 4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:02:54 @base.py:285]\u001b[0m Epoch 38 (global_step 38000) finished, time:3 minutes 27 seconds.\n",
      "\u001b[32m[1211 23:02:54 @saver.py:79]\u001b[0m Model saved to output/model/model-38000.\n",
      "\u001b[32m[1211 23:02:54 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.885\n",
      "\u001b[32m[1211 23:02:54 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.16\n",
      "\u001b[32m[1211 23:02:54 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65926\n",
      "\u001b[32m[1211 23:02:54 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.9487\n",
      "\u001b[32m[1211 23:02:54 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.020557\n",
      "\u001b[32m[1211 23:02:54 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.92814\n",
      "\u001b[32m[1211 23:02:54 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 23:02:54 @base.py:275]\u001b[0m Start Epoch 39 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:26<00:00, 4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:06:20 @base.py:285]\u001b[0m Epoch 39 (global_step 39000) finished, time:3 minutes 26 seconds.\n",
      "\u001b[32m[1211 23:06:20 @saver.py:79]\u001b[0m Model saved to output/model/model-39000.\n",
      "\u001b[32m[1211 23:06:20 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.94\n",
      "\u001b[32m[1211 23:06:20 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.16\n",
      "\u001b[32m[1211 23:06:20 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64185\n",
      "\u001b[32m[1211 23:06:20 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.97605\n",
      "\u001b[32m[1211 23:06:20 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.01524\n",
      "\u001b[32m[1211 23:06:20 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.96081\n",
      "\u001b[32m[1211 23:06:20 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 23:06:20 @base.py:275]\u001b[0m Start Epoch 40 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:27<00:00, 4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:09:48 @base.py:285]\u001b[0m Epoch 40 (global_step 40000) finished, time:3 minutes 27 seconds.\n",
      "\u001b[32m[1211 23:09:48 @saver.py:79]\u001b[0m Model saved to output/model/model-40000.\n",
      "\u001b[32m[1211 23:09:48 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.925\n",
      "\u001b[32m[1211 23:09:48 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.13\n",
      "\u001b[32m[1211 23:09:48 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65554\n",
      "\u001b[32m[1211 23:09:48 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96299\n",
      "\u001b[32m[1211 23:09:48 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.017747\n",
      "\u001b[32m[1211 23:09:48 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94524\n",
      "\u001b[32m[1211 23:09:48 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 23:09:48 @base.py:275]\u001b[0m Start Epoch 41 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:27<00:00, 4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:13:15 @base.py:285]\u001b[0m Epoch 41 (global_step 41000) finished, time:3 minutes 27 seconds.\n",
      "\u001b[32m[1211 23:13:15 @saver.py:79]\u001b[0m Model saved to output/model/model-41000.\n",
      "\u001b[32m[1211 23:13:15 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.945\n",
      "\u001b[32m[1211 23:13:15 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.115\n",
      "\u001b[32m[1211 23:13:15 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65083\n",
      "\u001b[32m[1211 23:13:15 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.95901\n",
      "\u001b[32m[1211 23:13:15 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.014438\n",
      "\u001b[32m[1211 23:13:15 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94457\n",
      "\u001b[32m[1211 23:13:15 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 23:13:15 @base.py:275]\u001b[0m Start Epoch 42 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:27<00:00, 4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:16:43 @base.py:285]\u001b[0m Epoch 42 (global_step 42000) finished, time:3 minutes 27 seconds.\n",
      "\u001b[32m[1211 23:16:43 @saver.py:79]\u001b[0m Model saved to output/model/model-42000.\n",
      "\u001b[32m[1211 23:16:43 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.935\n",
      "\u001b[32m[1211 23:16:43 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.17\n",
      "\u001b[32m[1211 23:16:43 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.63925\n",
      "\u001b[32m[1211 23:16:43 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.9848\n",
      "\u001b[32m[1211 23:16:43 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.014688\n",
      "\u001b[32m[1211 23:16:43 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.97012\n",
      "\u001b[32m[1211 23:16:43 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 23:16:43 @base.py:275]\u001b[0m Start Epoch 43 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:26<00:00, 4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:20:10 @base.py:285]\u001b[0m Epoch 43 (global_step 43000) finished, time:3 minutes 26 seconds.\n",
      "\u001b[32m[1211 23:20:10 @saver.py:79]\u001b[0m Model saved to output/model/model-43000.\n",
      "\u001b[32m[1211 23:20:10 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.945\n",
      "\u001b[32m[1211 23:20:10 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.115\n",
      "\u001b[32m[1211 23:20:10 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65427\n",
      "\u001b[32m[1211 23:20:10 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96082\n",
      "\u001b[32m[1211 23:20:10 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.015145\n",
      "\u001b[32m[1211 23:20:10 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94568\n",
      "\u001b[32m[1211 23:20:10 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 23:20:10 @base.py:275]\u001b[0m Start Epoch 44 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:29<00:00, 4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:23:39 @base.py:285]\u001b[0m Epoch 44 (global_step 44000) finished, time:3 minutes 29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:23:39 @saver.py:79]\u001b[0m Model saved to output/model/model-44000.\n",
      "\u001b[32m[1211 23:23:39 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.92\n",
      "\u001b[32m[1211 23:23:39 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.17\n",
      "\u001b[32m[1211 23:23:39 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64646\n",
      "\u001b[32m[1211 23:23:39 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.98414\n",
      "\u001b[32m[1211 23:23:39 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.017936\n",
      "\u001b[32m[1211 23:23:39 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.9662\n",
      "\u001b[32m[1211 23:23:39 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 23:23:39 @base.py:275]\u001b[0m Start Epoch 45 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|1000/1000[03:26<00:00, 4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:27:06 @base.py:285]\u001b[0m Epoch 45 (global_step 45000) finished, time:3 minutes 26 seconds.\n",
      "\u001b[32m[1211 23:27:06 @saver.py:79]\u001b[0m Model saved to output/model/model-45000.\n",
      "\u001b[32m[1211 23:27:06 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.935\n",
      "\u001b[32m[1211 23:27:06 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.145\n",
      "\u001b[32m[1211 23:27:06 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.6563\n",
      "\u001b[32m[1211 23:27:06 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.95538\n",
      "\u001b[32m[1211 23:27:06 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.013666\n",
      "\u001b[32m[1211 23:27:06 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94171\n",
      "\u001b[32m[1211 23:27:06 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 23:27:06 @base.py:275]\u001b[0m Start Epoch 46 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:29<00:00, 4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:30:36 @base.py:285]\u001b[0m Epoch 46 (global_step 46000) finished, time:3 minutes 29 seconds.\n",
      "\u001b[32m[1211 23:30:36 @saver.py:79]\u001b[0m Model saved to output/model/model-46000.\n",
      "\u001b[32m[1211 23:30:36 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.905\n",
      "\u001b[32m[1211 23:30:36 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.155\n",
      "\u001b[32m[1211 23:30:36 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.64166\n",
      "\u001b[32m[1211 23:30:36 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.97059\n",
      "\u001b[32m[1211 23:30:36 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.021072\n",
      "\u001b[32m[1211 23:30:36 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.94952\n",
      "\u001b[32m[1211 23:30:36 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 23:30:36 @base.py:275]\u001b[0m Start Epoch 47 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:27<00:00, 4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:34:04 @base.py:285]\u001b[0m Epoch 47 (global_step 47000) finished, time:3 minutes 27 seconds.\n",
      "\u001b[32m[1211 23:34:04 @saver.py:79]\u001b[0m Model saved to output/model/model-47000.\n",
      "\u001b[32m[1211 23:34:04 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.905\n",
      "\u001b[32m[1211 23:34:04 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.145\n",
      "\u001b[32m[1211 23:34:04 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.6431\n",
      "\u001b[32m[1211 23:34:04 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.95155\n",
      "\u001b[32m[1211 23:34:04 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.01937\n",
      "\u001b[32m[1211 23:34:04 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.93218\n",
      "\u001b[32m[1211 23:34:04 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 23:34:04 @base.py:275]\u001b[0m Start Epoch 48 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:26<00:00, 4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:37:30 @base.py:285]\u001b[0m Epoch 48 (global_step 48000) finished, time:3 minutes 26 seconds.\n",
      "\u001b[32m[1211 23:37:30 @saver.py:79]\u001b[0m Model saved to output/model/model-48000.\n",
      "\u001b[32m[1211 23:37:30 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.925\n",
      "\u001b[32m[1211 23:37:30 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.17\n",
      "\u001b[32m[1211 23:37:30 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.65837\n",
      "\u001b[32m[1211 23:37:30 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.96936\n",
      "\u001b[32m[1211 23:37:30 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.018805\n",
      "\u001b[32m[1211 23:37:30 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.95055\n",
      "\u001b[32m[1211 23:37:30 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 23:37:30 @base.py:275]\u001b[0m Start Epoch 49 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|##########|1000/1000[03:26<00:00, 4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 23:40:57 @base.py:285]\u001b[0m Epoch 49 (global_step 49000) finished, time:3 minutes 26 seconds.\n",
      "\u001b[32m[1211 23:40:57 @saver.py:79]\u001b[0m Model saved to output/model/model-49000.\n",
      "\u001b[32m[1211 23:40:57 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_fake: 0.915\n",
      "\u001b[32m[1211 23:40:57 @monitor.py:467]\u001b[0m GAN_loss/discrim/accuracy_real: 0.15\n",
      "\u001b[32m[1211 23:40:57 @monitor.py:467]\u001b[0m GAN_loss/discrim/loss: 0.63902\n",
      "\u001b[32m[1211 23:40:57 @monitor.py:467]\u001b[0m GAN_loss/gen/final-g-loss: 0.99413\n",
      "\u001b[32m[1211 23:40:57 @monitor.py:467]\u001b[0m GAN_loss/gen/klloss: 0.014602\n",
      "\u001b[32m[1211 23:40:57 @monitor.py:467]\u001b[0m GAN_loss/gen/loss: 0.97953\n",
      "\u001b[32m[1211 23:40:57 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[1211 23:40:57 @base.py:275]\u001b[0m Start Epoch 50 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|########  |807/1000[02:47<00:39, 4.88it/s]"
     ]
    }
   ],
   "source": [
    "gan.fit(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tgan.model.TGANModel at 0x7fd70ba75b50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "gan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1211 20:25:40 @model.py:792]\u001b[0m The indicated path already exists. Use `force=True` to overwrite.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir('tgan_100')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gan.save('tgan_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = np.load('./../generated_data_v1/us_import1/pos_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "gan.prepare_sampling()\n",
    "samples = gan.sample(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Carrier</th>\n",
       "      <th>ConsigneePanjivaID</th>\n",
       "      <th>HSCode</th>\n",
       "      <th>PortOfLading</th>\n",
       "      <th>PortOfUnlading</th>\n",
       "      <th>ShipmentDestination</th>\n",
       "      <th>ShipmentOrigin</th>\n",
       "      <th>ShipperPanjivaID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>490</td>\n",
       "      <td>799</td>\n",
       "      <td>681</td>\n",
       "      <td>264</td>\n",
       "      <td>61</td>\n",
       "      <td>125</td>\n",
       "      <td>84</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>2437</td>\n",
       "      <td>681</td>\n",
       "      <td>263</td>\n",
       "      <td>61</td>\n",
       "      <td>125</td>\n",
       "      <td>44</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>561</td>\n",
       "      <td>2983</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>96</td>\n",
       "      <td>16</td>\n",
       "      <td>2506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>2859</td>\n",
       "      <td>1248</td>\n",
       "      <td>153</td>\n",
       "      <td>61</td>\n",
       "      <td>125</td>\n",
       "      <td>83</td>\n",
       "      <td>2226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>223</td>\n",
       "      <td>737</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>39</td>\n",
       "      <td>88</td>\n",
       "      <td>36</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>99</td>\n",
       "      <td>541</td>\n",
       "      <td>924</td>\n",
       "      <td>145</td>\n",
       "      <td>37</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>99</td>\n",
       "      <td>116</td>\n",
       "      <td>897</td>\n",
       "      <td>181</td>\n",
       "      <td>60</td>\n",
       "      <td>124</td>\n",
       "      <td>16</td>\n",
       "      <td>2564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>286</td>\n",
       "      <td>573</td>\n",
       "      <td>897</td>\n",
       "      <td>135</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>286</td>\n",
       "      <td>2626</td>\n",
       "      <td>558</td>\n",
       "      <td>250</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>2815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>262</td>\n",
       "      <td>541</td>\n",
       "      <td>1601</td>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>96</td>\n",
       "      <td>16</td>\n",
       "      <td>2762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Carrier ConsigneePanjivaID HSCode PortOfLading PortOfUnlading  \\\n",
       "0      490                799    681          264             61   \n",
       "1      109               2437    681          263             61   \n",
       "2      561               2983     16           60             46   \n",
       "3       99               2859   1248          153             61   \n",
       "4      223                737      1          159             39   \n",
       "..     ...                ...    ...          ...            ...   \n",
       "95      99                541    924          145             37   \n",
       "96      99                116    897          181             60   \n",
       "97     286                573    897          135             35   \n",
       "98     286               2626    558          250              8   \n",
       "99     262                541   1601           60             46   \n",
       "\n",
       "   ShipmentDestination ShipmentOrigin ShipperPanjivaID  \n",
       "0                  125             84              898  \n",
       "1                  125             44             1042  \n",
       "2                   96             16             2506  \n",
       "3                  125             83             2226  \n",
       "4                   88             36              206  \n",
       "..                 ...            ...              ...  \n",
       "95                  86             16             1130  \n",
       "96                 124             16             2564  \n",
       "97                 100             16              317  \n",
       "98                  22             39             2815  \n",
       "99                  96             16             2762  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|          |235/?[00:14<00:00,16.47it/s]      \n"
     ]
    }
   ],
   "source": [
    "X = gan.sample(real_data.shape[0])\n",
    "\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0631682717155893"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_gen = eval_module.calculate_MI(X)\n",
    "mi_real = eval_module.calculate_MI(real_data)\n",
    "np.mean(np.array(mi_gen) - np.array(mi_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2680412371134021,\n",
       " 0.302828618968386,\n",
       " 0.30119047619047623,\n",
       " 0.4731182795698925,\n",
       " 0.4444444444444444,\n",
       " 0.4274809160305344,\n",
       " 0.4421052631578948,\n",
       " 0.2933664420007095]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_module.check_diversity(X, domain_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2147821208505578,\n",
       " 3.2407743906330735,\n",
       " 2.741984795776964,\n",
       " 0.8222966023558549,\n",
       " 0.16526206785331582,\n",
       " 0.4770258356556423,\n",
       " 0.5178967761797394,\n",
       " 3.4345104859836244]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_module.check_KLDiv(real_data, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ddatta/Code/experimentalGAN/evaluator/saved_model/us_import1/ad_if.pkl\n",
      "IsolationForest(contamination=0.01, n_jobs=40, verbose=True)\n",
      "(47200, 8)\n",
      ">> (47200, 8654)\n",
      "(47200, 8654)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03661016949152542"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_module.check_relative_anomaly_score( test_data = X, DIR ='us_import1', domain_dims = domain_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
